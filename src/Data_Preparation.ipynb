{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "csv_file_path = 'https://raw.githubusercontent.com/emitterl/AA-project-team-6/main/charging_sessions.csv'\n",
    "\n",
    "df = pd.read_csv(csv_file_path, delimiter=',', quotechar='\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Help functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for creating the table userInput \n",
    "def parse_user_inputs(row):\n",
    "    \n",
    "    user_inputs = row['userInputs']\n",
    "    id = row['id']\n",
    "\n",
    "    if isinstance(user_inputs, str):\n",
    "        try:\n",
    "            # Konvertieren des Strings in ein Python-Dictionary\n",
    "            user_inputs_data = ast.literal_eval(user_inputs)\n",
    "\n",
    "            for entry in user_inputs_data:\n",
    "                entry['reference_id'] = id\n",
    "            \n",
    "            return user_inputs_data\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler beim Parsen von userInputs fÃ¼r ID {id}: {e}\")\n",
    "            return []\n",
    "    else:\n",
    "        return []\n",
    "    \n",
    "\n",
    "# Function for converting the time zone\n",
    "def convert_timezone(time):\n",
    "    if pd.notna(time):\n",
    "        return time.tz_convert('America/Los_Angeles')\n",
    "    return time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the data types in charging_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['id'] = df['id'].astype(str)\n",
    "df['connectionTime'] = pd.to_datetime(df['connectionTime'], utc=True, errors='coerce').apply(convert_timezone)\n",
    "df['disconnectTime'] = pd.to_datetime(df['disconnectTime'], utc=True, errors='coerce').apply(convert_timezone)\n",
    "df['doneChargingTime'] = pd.to_datetime(df['doneChargingTime'], utc=True, errors='coerce').apply(convert_timezone)\n",
    "df['kWhDelivered'] = df['kWhDelivered'].astype(float)\n",
    "df['sessionID'] = df['sessionID'].astype(str)\n",
    "df['siteID'] = df['siteID'].astype(str)\n",
    "df['spaceID'] = df['spaceID'].astype(str)\n",
    "df['stationID'] = df['stationID'].astype(str)\n",
    "df['timezone'] = df['timezone'].astype(str)\n",
    "df['userID'] = df['userID'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the data set - main DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete columns Unnamed, stationID, sessionID   \n",
    "df.drop(df.columns[df.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\n",
    "df.drop(['sessionID', 'stationID', 'timezone'], axis=1, inplace=True)\n",
    "\n",
    "# Delete all duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Set doneChargingTime to disconnectTime wherever doneChargingTime is later than disconnectTime\n",
    "df.loc[df['doneChargingTime'] > df['disconnectTime'], 'doneChargingTime'] = df['disconnectTime']\n",
    "\n",
    "# Delete doneChargingTime wherever it is before connectionTime\n",
    "df.loc[df['doneChargingTime'] < df['connectionTime'], 'doneChargingTime'] = pd.NaT\n",
    "\n",
    "# Create DataFrame user_inputs_df\n",
    "user_inputs_list = df.apply(parse_user_inputs, axis=1)\n",
    "user_inputs_df = pd.DataFrame([item for sublist in user_inputs_list for item in sublist])\n",
    "\n",
    "# Delete userInputs, as they are in their own table\n",
    "df = df.drop('userInputs', axis=1)\n",
    "\n",
    "# Delete paymentRequired, because it is always true\n",
    "user_inputs_df = user_inputs_df.drop('paymentRequired', axis=1)\n",
    "\n",
    "# Handle missing values\n",
    "dfNan = df[df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the data types in user_inputs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_inputs_df['WhPerMile'] = user_inputs_df['WhPerMile'].astype(float)\n",
    "user_inputs_df['kWhRequested'] = user_inputs_df['kWhRequested'].astype(float)\n",
    "user_inputs_df['milesRequested'] = user_inputs_df['milesRequested'].astype(float)\n",
    "user_inputs_df['minutesAvailable'] = user_inputs_df['minutesAvailable'].astype(float)\n",
    "user_inputs_df['modifiedAt'] = pd.to_datetime(user_inputs_df['modifiedAt'], utc=True).apply(convert_timezone)\n",
    "user_inputs_df['requestedDeparture'] = pd.to_datetime(user_inputs_df['requestedDeparture'], utc=True).apply(convert_timezone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the data set - user inputs DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'merged_df' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "user_inputs_df = user_inputs_df.drop('userID', axis=1, errors='ignore')\n",
    "\n",
    "# Sort the user_inputs_df by 'reference_id' and 'modifiedAt' to get the latest entry for each ID\n",
    "user_inputs_df_sorted = user_inputs_df.sort_values(by=['reference_id', 'modifiedAt'], ascending=[True, False])\n",
    "\n",
    "# Keep only the most recent entry for each reference_id\n",
    "user_inputs_df_latest = user_inputs_df_sorted.drop_duplicates(subset=['reference_id'])\n",
    "\n",
    "# Merge the df with user_inputs_df_latest\n",
    "# Left join to ensure that all lines from df are retained\n",
    "merged_df = pd.merge(df, user_inputs_df_latest, how='left', left_on='id', right_on='reference_id')\n",
    "\n",
    "# Remove the 'reference_id' column as it is identical to 'id'\n",
    "merged_df.drop('reference_id', axis=1, inplace=True)\n",
    "\n",
    "# Removal of outliers\n",
    "merged_df.loc[merged_df.WhPerMile > 474.8, \"WhPerMile\"] = 474.8 # https://ev-database.org --> max 474.8 wh/mile\n",
    "merged_df.loc[merged_df.WhPerMile < 223.7, \"WhPerMile\"] = 223.7 # https://ev-database.org --> min 223.7 wh/mile\n",
    "merged_df.loc[merged_df.kWhRequested > 123, \"kWhRequested\"] = 123 # https://ev-database.org --> max 123 kwh\n",
    "merged_df = merged_df.drop(merged_df[merged_df.kWhRequested == 0].index, axis=0) #--> 0 not possible --> Del\n",
    "merged_df = merged_df.drop(merged_df[merged_df.milesRequested == 0].index, axis=0) #--> 0 not possible --> Del\n",
    "merged_df.loc[merged_df.milesRequested > 425.6, \"milesRequested\"] = 425.6  #--> # https://ev-database.org --> max 425,6 miles\n",
    "merged_df = merged_df.drop(merged_df[merged_df.minutesAvailable == merged_df.minutesAvailable.max()].index, axis=0) # Outlier --> Del\n",
    "\n",
    "\n",
    "%store merged_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
