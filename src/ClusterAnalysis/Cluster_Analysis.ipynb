{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "from data_preparation import merged_df\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.cluster.hierarchy as sc\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "- drop IDs and not needed columns, and convert time values into hours\n",
    "- Create sample from dataset as original dataset is too big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_df = merged_df.copy()\n",
    "\n",
    "dropped_df.drop('id', axis=1, inplace=True)\n",
    "dropped_df.drop('siteID', axis=1, inplace=True)\n",
    "dropped_df.drop('spaceID', axis=1, inplace=True)\n",
    "dropped_df.drop('userID', axis=1, inplace=True)\n",
    "dropped_df.drop('modifiedAt', axis=1, inplace=True)\n",
    "dropped_df.drop('requestedDeparture', axis=1, inplace=True)\n",
    "dropped_df.drop('WhPerMile', axis=1, inplace=True)\n",
    "dropped_df['connectionTime'] =  dropped_df['connectionTime'].dt.hour\n",
    "dropped_df['disconnectTime'] =  dropped_df['disconnectTime'].dt.hour\n",
    "dropped_df['doneChargingTime'] =  dropped_df['doneChargingTime'].dt.hour\n",
    "dropped_df = dropped_df.dropna()\n",
    "\n",
    "dropped_df = dropped_df.sample(n=3_000, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaled = scaler.fit_transform(dropped_df)\n",
    "scaled_df = pd.DataFrame(scaled, columns=dropped_df.columns, index=dropped_df.index)\n",
    "\n",
    "sns.pairplot(data=scaled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many clusters should we use?\n",
    "1. Plot residual loss for different number of clusters, find 'elbow' and select corresponding number of clusters\n",
    "2. Use hierarchical clustering to detect suitable braching and corresponding number of clusters\n",
    "\n",
    "### Residual loss plot -> number of clusters between 2 and 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_max = 15\n",
    "clusters = []\n",
    "losses = []\n",
    "\n",
    "for k in range(k_max):\n",
    "    model = KMeans(n_clusters=k+1, n_init='auto')\n",
    "    model.fit(scaled)\n",
    "    clusters.append(k+1)\n",
    "    losses.append(model.inertia_)\n",
    "\n",
    "plt.figure(figsize=(10, 5))  \n",
    "plt.plot(clusters, losses)\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchal Clustering -> number of clusters = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 7))  \n",
    "plt.title(\"Dendrograms\")  \n",
    "plt.title('Dendrogram')\n",
    "plt.xlabel('Sample index')\n",
    "plt.ylabel('Euclidean distance')\n",
    "sc.dendrogram(sc.linkage(scaled, method='ward'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Means with 3 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [\"one\", \"two\", \"three\"]\n",
    "three_means = KMeans(n_clusters=3, n_init='auto')\n",
    "three_means.fit(scaled)\n",
    "\n",
    "# match records to clusters by calling predict\n",
    "three_means.predict(scaled)\n",
    "scaled_df[\"three\"] = three_means.predict(scaled)\n",
    "scaled_df[\"three\"] = scaled_df[\"three\"].apply(lambda x: numbers[x])\n",
    "\n",
    "sns.pairplot(data=scaled_df, hue=\"three\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
