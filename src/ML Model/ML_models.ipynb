{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'model_df' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "\n",
    "%run ../model_preparation/import_model_data.ipynb\n",
    "%store -r model_df\n",
    "\n",
    "model_df['Year'] = model_df['time'].dt.year\n",
    "model_df['Month'] = model_df['time'].dt.month\n",
    "model_df['Day'] = model_df['time'].dt.day\n",
    "model_df['Hour'] = model_df['time'].dt.hour\n",
    "\n",
    "model_df.drop('time', axis=1, inplace=True)\n",
    "\n",
    "# Umwandlung kategorialer Variablen in Dummy-Variablen\n",
    "model_df = pd.get_dummies(model_df, columns=['Weekday', 'weather_description'])\n",
    "\n",
    "model_df['siteIDIsOne'] = model_df['siteID'] == '1'\n",
    "model_df.drop('siteID', axis=1, inplace=True)\n",
    "\n",
    "# Zielvariable und Merkmale trennen\n",
    "X = model_df.drop('occupied_count', axis=1)  # Merkmale\n",
    "y = model_df['occupied_count']               # Zielvariable\n",
    "\n",
    "# Aufteilen in Trainings- und Testdaten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durchschnittlicher Mean Squared Error während Kreuzvalidierung: 129.06939425013383\n",
      "Test Mean Squared Error: 126.79444817490875\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('scaling', StandardScaler()),\n",
    "    ('lin_reg', LinearRegression())\n",
    "])\n",
    "\n",
    "# Einstellen der Parameter für die Kreuzvalidierung\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Durchführen der Kreuzvalidierung\n",
    "scores = cross_val_score(pipeline, X_train, y_train, cv=kfold, scoring='neg_mean_squared_error')\n",
    "\n",
    "print(f\"Durchschnittlicher Mean Squared Error während Kreuzvalidierung: {np.mean(-scores)}\")\n",
    "\n",
    "\n",
    "# Trainieren des Modells mit allen Trainingsdaten\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "test_mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Test Mean Squared Error: {test_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Definieren der Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('poly', PolynomialFeatures()),\n",
    "    ('scaling', StandardScaler()),\n",
    "    ('ridge', Ridge())\n",
    "])\n",
    "\n",
    "# Hyperparameter für die Grid-Suche\n",
    "param_grid = {\n",
    "    'poly__degree': [3, 4],\n",
    "    'poly__interaction_only': [True, False],\n",
    "    'poly__include_bias': [True, False],\n",
    "    'ridge__alpha': [0.01, 0.1, 1], \n",
    "}\n",
    "\n",
    "# GridSearchCV auf den Trainingsdaten\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Beste Parameter und Modell\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Bewertung auf den Testdaten\n",
    "y_pred = best_model.predict(X_test)\n",
    "test_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(\"Beste Parameter:\", best_params)\n",
    "print(\"Test MSE:\", test_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desicion Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../model_preparation/import_model_data.ipynb\n",
    "%store -r model_df\n",
    "\n",
    "\n",
    "# Aufteilen der 'time'-Spalte in Jahr, Monat, Tag und Stunde\n",
    "model_df['Year'] = model_df['time'].dt.year\n",
    "model_df['Month'] = model_df['time'].dt.month\n",
    "model_df['Day'] = model_df['time'].dt.day\n",
    "model_df['Hour'] = model_df['time'].dt.hour\n",
    "model_df.drop('time', axis=1, inplace=True)\n",
    "\n",
    "# Ich halte mögliche Vergleiche wie Weekday >= 5 sinnvoll, um Wochentag und Wochenende unterscheiden zu können\n",
    "weekday_map = {'Monday': 0, 'Tuesday': 1, 'Wednesday': 2, 'Thursday': 3, 'Friday': 4, 'Saturday': 5, 'Sunday': 6}\n",
    "model_df['Weekday'] = model_df['Weekday'].map(weekday_map)\n",
    "\n",
    "# Umwandlung kategorialer Variablen in Dummy-Variablen\n",
    "model_df = pd.get_dummies(model_df, columns=['weather_description'])\n",
    "\n",
    "# Zielvariable und Merkmale trennen\n",
    "X = model_df.drop('occupied_count', axis=1)\n",
    "y = model_df['occupied_count']\n",
    "\n",
    "# Aufteilen in Trainings- und Testdaten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Parameter für GridSearchCV\n",
    "param_grid = {\n",
    "    'max_depth': [5, 7, 10],\n",
    "    'min_samples_leaf': [50, 100, 500, 1000, 1500],\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "# GridSearchCV auf den Trainingsdaten\n",
    "grid_search = GridSearchCV(DecisionTreeRegressor(random_state=42, ccp_alpha=0.1), param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Beste Parameter und Modell\n",
    "best_params = grid_search.best_params_\n",
    "best_tree = grid_search.best_estimator_\n",
    "\n",
    "plt.figure(figsize=(30, 15))\n",
    "plot_tree(best_tree, feature_names=X.columns, filled=True)\n",
    "plt.savefig('decision_tree.svg', format='svg')\n",
    "plt.close() \n",
    "\n",
    "# Bewertung auf den Testdaten\n",
    "y_pred = best_tree.predict(X_test)\n",
    "test_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(\"Beste Parameter:\", best_params)\n",
    "print(\"Test MSE:\", test_mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AA-Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
